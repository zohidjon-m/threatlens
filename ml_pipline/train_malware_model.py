import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import joblib
import os
import sys

# --- CONFIGURATION AND PATHS ---
# NOTE: Adjust this path to where you placed the EMBER data files (e.g., X_train.npy, y_train.npy)
EMBER_DATA_PATH = "C:/Users/Natalia Perez/threatlens/Natalia_ML_Shap/ember_data/" 
# Asegúrate que los nombres de archivo coincidan con lo que descargaste.
FEATURES_FILE = os.path.join(EMBER_DATA_PATH, 'train_ember_2018_v2_features.parquet')
#LABELS_FILE = os.path.join(EMBER_DATA_PATH, 'train_labels.csv')
MODEL_OUTPUT_PATH = "lgbm_malware_detector.pkl"
RANDOM_SEED = 42

# --- FUNCIÓN DE CARGA ACTUALIZADA ---
def load_ember_data():
    print("Loading data using Pandas (COMPLETE Parquet format)...")
    
    try:
        # 1. Load the COMPLETE Parquet file
        # Esto carga todas las características (X) Y la columna 'label' (y)
        df_complete = pd.read_parquet(FEATURES_FILE) 
        print(f"Complete DataFrame loaded. Shape: {df_complete.shape}")
        
        print("\nColumn Names in Parquet:")
        print(df_complete.columns.tolist())
        # 2. Separate Labels (y) and Features (X)
        # Asegúrate de que la columna se llame 'label' (como es estándar en EMBER)
        y_all = df_complete['Label'].values
        X_df = df_complete.drop(columns=['Label']) 
        
        # 3. Clean and Align Data
        # Filter out the unlabeled samples (labels == -1)
        valid_indices = y_all != -1
        
        # Filter both X and y
        X = X_df[valid_indices].values
        y = y_all[valid_indices]
        
    except FileNotFoundError:
        print(f"--- ERROR CRÍTICO: ARCHIVO NO ENCONTRADO ---")
        print(f"Ruta buscada: {FEATURES_FILE}")
        print("Asegúrate de que el archivo Parquet exista en la carpeta './ember/'.")
        return None, None
    except Exception as e:
        print(f"An error occurred during data loading: {e}")
        return None, None
    
    print(f"Data successfully processed. Total valid samples (0/1): {len(X)}")
    print(f"Features (X) shape after cleaning: {X.shape}")
    return X, y

# --- MODEL TRAINING FUNCTION ---

def train_lgbm_model(X, y):
    """
    Trains the LightGBM classifier using the loaded EMBER features.
    """
    print("\nStarting LightGBM model training...")
    
    # 1. Data Splitting: 80% Train, 20% Test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y
    )
    
    # 2. LightGBM Configuration (optimized for binary classification)
    lgbm_params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'n_estimators': 1000, 
        'learning_rate': 0.05,
        'seed': RANDOM_SEED,
        'n_jobs': -1, # Use all available cores
        'verbose': -1 # Suppress detailed output during training
    }
    
    # 3. Model Training with Early Stopping
    model = lgb.LGBMClassifier(**lgbm_params)
    
    model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        eval_metric='auc',
        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=True)]
    )
    
    # 4. Final Evaluation (Focusing on AUC, a robust metric for imbalanced data)
    test_proba = model.predict_proba(X_test)[:, 1] # Probability of being malware (class 1)
    auc_score = roc_auc_score(y_test, test_proba)
    
    print(f"\n--- Training Complete ---")
    print(f"Area Under Curve (AUC) Score on Test Set: {auc_score:.4f}")
    
    return model

# --- MAIN EXECUTION ---

if __name__ == '__main__':
    # 1. Load Data
    X, y = load_ember_data()

    # 2. Train Model
    trained_model = train_lgbm_model(X, y)
    
    # 3. Save the Trained Model
    print(f"\nSaving the trained model to {MODEL_OUTPUT_PATH}...")
    joblib.dump(trained_model, MODEL_OUTPUT_PATH)
    print("Model saved successfully! Ready for inference (Semana 2).")